---
title: "Clean data frame"
author: "Robin"
date: "02/06/2019"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = FALSE)

# User parameters
min_age = 0
max_age = 40
wdir = '~/Documents/Github/fractal-eye-analyses/'
cleaned_precision_dat = 0 # Are you using precision data that have already been cleaned?
```

# Where do you want to save data?

```{r}
out_dir = paste(wdir, 'data/', sep = '')
file_name = paste(format(Sys.time(), "%Y %b %d"), 'cleaned_multilevel_data', sep = '-')
```

```{r}
out_dir
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(knitr)
source('/Users/sifre002/Documents/GitHub/fractal-eye-analyses/analysis/Rfuncs/compareNA.R')
```

# Read data

```{r warnings=FALSE,message=FALSE}
# List of ET sessions linked with DOB, Sex, etc. 
particList = read_csv(file = paste(wdir, 'data_audit/Dissertation_ParticList.csv', sep=''))

# Concatenated output Output from pipeline in fractal-eye-analyses-MFDFA/
h <- read_csv(file = paste(wdir, 'data/h_out.txt', sep = ''))

# Calibration precision spreadsheet  
precision_info <- read.csv( paste(wdir, 'data_for_calver/data_d_output_reformatted.csv', sep=''), stringsAsFactors = FALSE )

# Face-looking data 
aoi_data<- read.csv( paste(wdir, 'data/face_out.txt', sep ='') )
```

```{r}
particList = particList %>% 
  select(CandID, PSCID, DOB, Sex, et_collected, et_age, et_date, cohort2)
```

# Format DFA output

Don't remove rows until the very end

```{r echo=TRUE}
nrow(h)
```

```{r}
# Generate variables to help with analysis
h=h %>%
  # Create variable for Participant ID (currently combined with session #)
  mutate(Participant = paste(lapply(strsplit(id, '_'), '[', 1), lapply(strsplit(id, '_'), '[', 2), sep='_')) %>%
  relocate(Participant, .after=id) %>% 
  # Create Dummies for CalVer & Pixelated
  mutate(CalVer=ifelse(grepl('Center|Left|Right', movie), 1, 0),
         Pix=ifelse(grepl('S', movie), 1, 0)) %>%
  mutate(use_h = ifelse(r2>=0.9, 1, 0)) 
  
  
# Calculate spectrum width for each row (id, movie, seg)
h = h %>%
  gather(hq, hq_val, contains('Hq')) %>%
  group_by(id, movie, seg) %>%
  mutate(min_hq = min(hq_val, na.rm=TRUE),
         max_hq = max(hq_val, na.rm = TRUE),
         spect_width = max_hq-min_hq) %>%
  spread(hq, hq_val) %>%
  ungroup() %>%
  # re-order the Hq columns  [-5 -3 -1 0 3 5] 
 relocate(`Hq-5`, .before = `Hq-1`) %>%
 relocate(Hq0, .after =`Hq-3`)

# Merge w/ participant info 
h = h %>%
  # Create variable for Participant ID (currently combined with session #)
  mutate(Participant = paste(lapply(strsplit(id, '_'), '[', 1), lapply(strsplit(id, '_'), '[', 2), sep='_')) %>%
  left_join(particList, by=c('id'='et_collected')) %>%
 # Variable to keep track of if theyre in participant list
  mutate(particList = ifelse(Participant %in% particList$PSCID, 1, 0)) 
```

# Flag time series for exclusion

Flag participants in `h_out.txt` who are a) not in the participant list, and b) not in age-range

```{r}
# Log who was removed 
h = h %>%
  mutate(remove = ifelse(particList==0, 1, 0),
         reason = ifelse(particList==0, 'Not in participant list', ''),
         remove = ifelse(et_age<min_age | et_age>max_age, 1, remove),
         reason = ifelse((et_age<min_age | et_age>max_age) & reason=='', 'Age range', reason)) %>% # Only update reason if it was not already flagged
  mutate(reason = ifelse(is.na(reason), '', reason))
```

```{r}
#Creates precisionInfo dataframe of average calibration XY precision information for each kid who made it through CalVer processing.
#Those with precision that is worse than threshold are coded as 999
# SKIP THIS PART IF YOU USING CALVER DATA THAT ALREADY HAVE BEEN CLEANED
if (cleaned_precision_dat==0) {
  source(paste(wdir, 'processing/clean_calver.R', sep = ''))
  calver=clean_calver(precision_info)
  calver_thresh=calver[[1]]
  AvgPrecision=calver[[2]]
}

# Clean AvgPrecision
AvgPrecision = AvgPrecision %>%
  mutate(id= paste(sapply(strsplit(id, '_'), '[', 1), sapply(strsplit(id, '_'), '[', 2), sapply(strsplit(id, '_'), '[', 3), sep = '_'))


# Merge Precision data with H data 
h= h %>% left_join(AvgPrecision, by='id') 
```

Flag participants in `h_out.txt` who are a) missing calver or b) have bad calver

```{r echo=TRUE}
h = h %>% 
  mutate(remove = ifelse(compareNA(AvgPrecision, 999), 1, remove),
         reason = ifelse(compareNA(AvgPrecision, 999) & reason=='', 'Bad Calver', reason),
         remove = ifelse(is.na(AvgPrecision), 1, remove),
         reason = ifelse(is.na(AvgPrecision) & reason=='', 'Missing Calver', reason)) 

```

Check for Wonky calver

```{r}
h %>% 
  filter(AvgPrecision < 0) %>%
  select(id, AvgPrecision) %>%
  distinct()
```

Flag row in `h_out.txt` for high interpolation

From manuscript:\
\> After visualizing the distribution, the 80th quantile threshold for the sample's proportion interpolated was calculated (0.115) and segments with a proportion exceeding that value were excluded from analyses

```{r echo=TRUE}
interp_thresh = h %>%
  # Calculate 80th percentile of time series from visits that have good calibration 
  filter(compareNA(remove,0)) %>%
  pull(propInterp) %>%
  quantile(c(.8))
interp_thresh
```

```{r}
h = h %>%
  mutate(remove = ifelse(propInterp > interp_thresh[1], 1, remove),
         reason = ifelse(propInterp > interp_thresh[1] & reason=='', 'propInterp', reason))
```

Flag row in `h_out.txt` if the residual missing data was more than the 80th percentile threshold
```{r}
missing_thresh = h %>%
  filter(compareNA(remove,0)) %>%
  pull(propMissing)%>%
  quantile(c(.8))
missing_thresh
```

```{r}
h = h %>% 
  mutate(remove = ifelse(propMissing > missing_thresh[1], 1, remove),
         reason = ifelse(propMissing > missing_thresh[1] & reason=='', 'propMissing', reason))
```


Flag row in `h_out.txt` if the time series was too short (\<800 frames, which is roughly `r 800*3.33` ms)

```{r}
min_dur = 800*3.33

h = h %>%
  mutate(remove = ifelse(longestFixDur<min_dur, 1, remove),
         reason = ifelse(longestFixDur<min_dur & reason=='', 'Fixation too short', reason))

```

Flag row in `h_out.txt` if the the $r^2$ indicated that there was non-linear scaling function

```{r}
h = h %>%
  mutate(remove = ifelse(r2<0.9, 1, remove),
         reason = ifelse(r2<0.9 & reason=='', 'Bad R2', reason))
```

Reasons a row was removed

```{r}
h %>% filter(remove==1) %>% pull(reason) %>% unique()
```

# Flow on exclusion
Note - start with full sample only including those with the right age-range. These were removed: 
```{r echo = TRUE}
h %>% filter(reason=='Age range') %>% select(id, et_age) %>% arrange(id) %>% distinct()
h = h%>%filter(reason!='Age range')
```

```{r}
removed = h %>% filter(remove==1)
h_clean = h %>% filter(remove==0)
```


```{r}
n_females = h %>% select(Participant, Sex) %>% distinct() %>% pull(Sex) 
n_females = sum(n_females=='female')

age_summ = h %>% select(id, et_age)  %>% distinct() %>% 
   summarize(mean_age = mean(et_age),
             min_age = min(et_age),
             max_age = max(et_age))
             

```

<b>Original Sample</b>.  `r nrow(h)` time-series of eye-tracking data were collected from `r length(unique(h$Participant))` `r round(age_summ$min_age, 2)`-`r round(age_summ$max_age, 2)`-month-old infants (`r n_females` females, mean age= `r age_summ$mean_age` months) across `r length(unique(h$id))` visits to the lab.  

```{r}
# How many visits per partipants 
vis = h %>%
  select(Participant, id) %>%
  distinct() %>%
  group_by(Participant) %>%
  summarize(n=n())
```

As part of a planned missingness design, children contributed between `r min(vis$n)` and `r max(vis$n)` waves of data across this age span (mean `r round(mean(vis$n),2)` waves) during visits to the lab. 


## Outside age-range

```{r}
removed_age = removed  %>%
  filter(reason=='Age range') %>% 
  select(id, et_age) %>% distinct()
removed_age
```

##Missing Calver

```{r}
removed_missingcalver = removed %>%
  filter(reason=='Missing Calver') %>% 
  select(id) %>% distinct()
removed_missingcalver
```



## Bad Calver

```{r}
removed_badcalver = removed %>%
  filter(reason=='Bad Calver') %>% 
  select(id) %>% distinct()
removed_badcalver
```
<b>Quality-control exclusion criteria</b>. Infants’ eyes were calibrated to the eye-tracking equipment at the beginning of each visit, using the manufacturer’s five-point calibration procedure. Precision, or the distance between repeated samples of gaze points58, was included given that it is a measure of variability and thus is likely to influence DFA calculations that quantify nested patterns of variability. To measure the eye-tracker’s precision throughout the experiment, experimental trials were interleaved with audio-visual attention cues. Precision was included as a quality-control exclusion criterion due to its potential to influence fractal structure, given that it is an index of variation around a target stimulus. Audio-visual attention cues were presented at 3 time-points during each eye-tracking visit: at the beginning, interleaved with the Social and Pixelated movies, and at the end. Infants’ longest contiguous raw eye-tracking data for all available Attention Cue trials were analyzed for precision. Data from eye-tracking sessions with Root Mean Square Error of Approximation (RMSEA) values two standard deviations or more above the sample mean (indicating poor precision) were excluded. As such, data from eye-tracking sessions with an average RMSEA (averaged across X and Y axes for both eyes) greater than `r round(calver_thresh,2)` degrees of visual angle were excluded from analyses. 

As a result, data from `r length(unique(removed_badcalver$Participant))` participants, `r length(unique(removed_badcalver$id))` eye-tracking visits, totaling `r nrow(removed_badcalver)` time-series were excluded from future analyses. For the remaining eye-tracking visits, the average precision was `r mean(h_clean$AvgPrecision)`° of visual angle.



## High interpolation levels

```{r}
remove_interp = removed %>%
  filter(reason == 'propInterp') %>%
  select(id, movie, seg)

```
Blinks were identified using a noise-based algorithm. All data missing as a result of blinks (less than 200 ms)
were linearly interpolated using data from the last valid sample before the start of the blink, and the first valid sample after the end of the blink (mean proportion interpolated = `r round(mean(h_clean$propInterp),2)`, range `r min(h_clean$propInterp)`–`r max(h_clean$propInterp)`). \

## Too much residual missing
```{r}
remove_missing = removed %>% 
  filter(reason == 'propMissing') %>%
  select(id, Participant, movie, seg)
```

```{r}
# Calculate mean % missing for the time series that have not yet been excluded 
temp = h %>% 
  filter(!grepl('Calver|participant list|propInterp', reason)) %>%
  pull(propMissing)
```

After interpolation, infants had an average proportion of `r mean(temp)` (range `r min(temp)`–`r max(temp)`) residual missing data per segment. Given past work suggesting too much aggregation can bias detrended fluctuation analysis (e.g.,20), we chose a stringent quality control threshold for the permissible proportion interpolated for each segment. 

After visualizing the distribution, the 80th quantile threshold for the sample’s proportion interpolated was calculated (`r round(interp_thresh[1], 3)`) and segments with a proportion exceeding that value were excluded from analyses; data from an additional `r length(unique(remove_missing$Participant))` infant, `r length(unique(remove_missing$id))` eye-tracking session, totaling `r nrow(remove_missing)` time-series were removed from future analyses. The mean proportion of residual missing data for the remaining sample was `r mean(h_clean$propMissing)`. Proportions of interpolated and residual missing data were entered into all models as covariates. 


## Fixation too short

```{r}
removed_fix = removed %>%
  filter(reason=='Fixation too short') %>% 
  select(Participant, id, movie, seg) 
removed_fix
```

Based on ----, we removed time series with fewer than 800 data points. Accordingly, data from an additional `r length(unique(removed_fix$Participant))` participants, `r length(unique(removed_fix$id))` eye-tracking visits, totaling to `r nrow(removed_fix)` segments were excluded from future analyses


## Bad R2

```{r}
removed_r2 = removed %>%
  filter(reason=='Bad R2') %>% 
  select(Participant, id, movie, seg) 
removed_r2
```

Finally, .... ata from an additional `r length(unique(removed_r2$Participant))` participants, `r length(unique(removed_r2$id))` eye-tracking visits, totaling to `r nrow(removed_r2)` segments were excluded from future analyses

```{r}
knit_exit()
```

# Clean AOI data & Merge with H data

```{r echo=TRUE}
aoi_data = aoi_data %>%
  dplyr::select(id,
          movie,
          seg,
          longestFix_aoi = longestFixDur,
          faceCount, otherCount) %>%
  mutate(id=as.character(id),
         movie=as.character(movie))

aoi_data2 = aoi_data %>% filter(longestFix_aoi!=-9999) 


h = h %>%
  left_join(aoi_data, by = c('id', 'movie', 'seg')) %>%
  mutate(propFace_seg = faceCount / (faceCount + otherCount))
```

# Save output

```{r echo=TRUE}
today = format(Sys.Date(), format="%Y-%m-%d")
write.csv(h, paste(out_dir, today, '-clean_h.csv', sep = ''))
```

```{r}
knit_exit()
```

# Create person-, visit-, and movie-centered variables. These are used to parse variance for modelling.

## Grand means

```{r echo = TRUE}
# Get grand mean for average age
AveAge = h2 %>%
  # Pull age for each person's visit (average age calculated so that their age at each visit is weighted online once)
  group_by(id)%>%
  summarise(Age = unique(age)) %>%
  # Calculate sample's average Age 
  summarise(Age = mean(Age) )

# Get grand mean for average longest fix
aveLongFix=mean(h2$longestFixDur)
avePrec=mean(h2$Precision_RMS_X_Y)
avePropFace = mean(h2$propFace_seg, na.rm = TRUE)

# Create varaible for person's age centered at grand mean 
h2=h2%>%
 mutate(Age_centeredGrandmean=as.numeric(age-AveAge$Age)) 
```

-   Average age = `r AveAge`\
-   Average longest fix duration = `r aveLongFix`\
-   Average calver precision = `r avePrec`\
-   Average % face-looking = `r avePropFace`

## Person-level variables

```{r echo = TRUE}
# Creating level 3 (person) variables:
# Average age: Participant's average age (weight each visit once)
# Average Interpolated: mean prop interp
# Average precision: mean precision (weight each visit once)
# Average longest fix: mean longest fix, centered on grand mean
personLevel_var=h2%>%
  group_by(Participant)%>%
  summarise(AveAge_person=mean(Age_centeredGrandmean),
            AveInterp_person=mean(propInterp),
            AveMissing_person=mean(propMissing),
            AvePrecision_person = mean(Precision_RMS_X_Y),
            AveLongestFix_person=mean(longestFixDur),
            AvePropFace_person = sum(faceCount, na.rm = TRUE) / ( sum(faceCount, na.rm = TRUE) + sum(otherCount, na.rm = TRUE) ),
            n_person=n())
```

# Session-level variables

```{r}
# Session age = Age_centeredGrandmean (no within-session variability)
# Average interpolated: Mean prop interp, for the session
# Average Missing: Mean prop Missing
# Average longest fix: mean longest fix, centered on grand mean
# Average face looking: mean face looking for the session
sessionLevel_var = h2 %>%
  group_by(id) %>%
  summarise(AveInterp_session = mean(propInterp),
            AveMissing_session = mean(propMissing),
            AveLongestFix_session = mean(longestFixDur),
            AvePropFace_session = sum(faceCount, na.rm = TRUE) / 
              ( sum(faceCount, na.rm = TRUE) + sum(otherCount, na.rm = TRUE) ))

```

# Movie-level

```{r}
movieLevel_var = h2 %>%
  group_by(Participant, id, movie) %>%
  summarise(AveInterp_movie = mean(propInterp),
            AveMissing_movie = mean(propMissing),
            AveLongestFix_movie = mean(longestFixDur),
            AvePropFace_movie = sum(faceCount, na.rm = TRUE) / 
              (sum(faceCount, na.rm = TRUE) + sum(otherCount, na.rm = TRUE)) )
```

```{r}
# # # # # # # # # # # #
# Create centered variables 
# # # # # # # # # # # #

# Merge person-level
h3 = merge(h2, personLevel_var, by = 'Participant')
# Merge visit-level
h4 = merge(h3, sessionLevel_var, by = 'id')
# Merge movie-level
h5 = merge(h4, movieLevel_var, by = c('Participant', 'id', 'movie'))

# Create PERSON_LEVEL variables centered at GRAND MEAN
h5$propInterp_person_grandmeancentered = h5$AveInterp_person - mean(h5$propInterp)
h5$longestFix_person_grandmeancentered  = h5$AveLongestFix_person - mean(h5$longestFixDur)
h5$propFace_person_grandmeancentered  = h5$AvePropFace_person - mean(h5$propFace_seg, na.rm = TRUE)
h5$precision_person_grandmeancentered  = h5$AvePrecision_person - mean(h5$Precision_RMS_X_Y, na.rm=TRUE)
h5$age_centered_grandmean = h5$age - AveAge$Age

# Create VISIT-LEVEL variables centered at PERSON-LEVEL
h5$propInterp_session_groupmeancentered = h5$AveInterp_session - h5$AveInterp_person
h5$longestFix_session_groupmeancentered = h5$AveLongestFix_session - h5$AveLongestFix_person
h5$propFace_session_groupmeancentered = h5$AvePropFace_session - h5$AvePropFace_person
h5$precision_session_groupmeancentered = h5$Precision_RMS_X_Y - h5$AvePrecision_person # each visit has one Precision_RMS_X_Y

# Create MOVIE-LEVEL VARIABLES centered at VISIT-LEVEL
h5$propInterp_movie_groupmeancentered = h5$AveInterp_movie - h5$AveInterp_session
h5$longestFix_movie_groupmeancentered = h5$AveLongestFix_movie - h5$AveLongestFix_session
h5$propFace_movie_groupmeancentered = h5$AvePropFace_movie - h5$AvePropFace_session

# Create SEGMENT-LEVEL VARIABLES centered at MOVIE LEVEL
h5$propInterp_segment_groupmeancentered = h5$propInterp - h5$AveInterp_movie
h5$longestFix_segment_groupmeancentered = h5$longestFixDur - h5$AveLongestFix_movie
h5$propFace_segment_groupmeancentered = h5$propFace_seg - h5$AvePropFace_movie


# Code for error checking 
# test = h5 %>% filter(id == 'JE000053_03_01' & movie == '01_converted.avi')
# test$AveAge_person
# 
# 
# test = h5 %>% filter(id == 'JE000053_03_01') %>%
#   dplyr::select(id,movie,seg,
#                 AvePropFace_person, AvePropFace_session, AvePropFace_movie,
#                 faceCount,otherCount,propFace_seg, propFace_segment_groupmeancentered, 
#                 propFace_movie_groupmeancentered, propFace_session_groupmeancentered,propFace_person_grandmeancentered)
# 
# test = h5 %>% filter(id == 'JE000053_03_01') %>%
#   dplyr::select(id, movie, seg, 
#                 AvePropFace_person, AvePropFace_session, AvePropFace_movie,
#                 faceCount,otherCount,propFace_seg, propFace_segment_groupmeancentered, 
#                 propFace_movie_groupmeancentered, propFace_session_groupmeancentered,propFace_person_grandmeancentered)
# # test visit-level face avg 
# sum(test$faceCount, na.rm = TRUE) / (sum(test$faceCount, na.rm = TRUE)  + sum(test$otherCount, na.rm = TRUE))
# # Test movie-level face 
# a = test %>% filter(movie == '01_converted.avi') 
# sum(a$faceCount, na.rm = TRUE) / (sum(a$faceCount, na.rm = TRUE)  + sum(a$otherCount, na.rm = TRUE))
# # test - segment level prop face
# test[1, 'faceCount'] / (test[1, 'faceCount'] + test[1, 'otherCount'])
# test[1, 'propFace_seg']
# # test segment - level cnetering
# test[1, 'propFace_seg'] - test[1, 'AvePropFace_movie'] == test[1, 'propFace_segment_groupmeancentered']
# test[1, 'AvePropFace_movie'] - test[1, 'AvePropFace_session'] == test[1, 'propFace_movie_groupmeancentered']
# test[1, 'AvePropFace_session'] - test[1, 'AvePropFace_person'] == test[1, 'propFace_session_groupmeancentered']
# test[1, 'AvePropFace_person'] - avePropFace == test[1, 'propFace_person_grandmeancentered']


```

```{r}
# optional: save output
write_csv(x = h5, path = paste(out_dir, 'cleaned_data.csv', sep=''))
```
